<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Haihua Chen</title>
    <meta content="Haihua Chen" name="Haihua Chen">
    <link rel="shortcut icon" href="./favicon.ico" />
    <link href="style.css" rel="stylesheet" type="text/css">
    <script src="jquery-1.11.1.min.js" type="text/javascript"></script>  
  </head>
  <body>
    <div class="menu">
      <a href="https://haihua0913.github.io/index.html">Home</a> 
      <a href="#bio">Bio</a> 
      <a href="#news">News</a> 
      <a href="#grants">Grants</a>
      <a href="#publications">Publications</a>
      <a href="#teaching">Teaching</a>
      <a href="#awards"> Services</a> 
      <a href="#honors"> Honors</a>
      <a href="#team">Students</a>
      <a href="#resources"> Resources</a> 
      
      <!-- <a href="https://ruizhao26.github.io/index.html#code"> Code/Data</a>  -->
    </div>
    <div class="container">
      <table border="0" class="profile">
        <tbody>
          <tr>
            <td><img src="./images/personal/haihua-headshot.jpg" width="160" height="200"></td>
            <td style="width: 10px">&nbsp;</td>
            <td valign="top" width="500">
              <span class="name">Haihua Chen (陈海华)</span>
              <p class="information"><br>
                Assistant Professor, Data Science, <br>
                Affiliated in Health Informatics, <br>
                Director, <a href="https://www.idealab-coi.com">Intelligent Data Engineering & Analytics (IDEA) Labb</a> <br>
                <a href="https://datascience.unt.edu/people/haihua-chen.html">Deparmental webpage</a> <br>
                Department of Data Science <br>
                University of North Texas. <br>
                Office: E298A, Discovery Park <br>
                Address: 3940 North Elm, Suite E292 Denton, Texas 76203-5017
              </p>
              <!-- <p class="information">No.5 Yiheyuan Road, <br>
                Haidian District, Beijing, <br>
                Room 2728, Science Building #2, Peking University.
                </p> -->
              <!-- <p class="information"><strong>Address</strong>: E298A, Discovery Park</p> -->
              <p class="information"><strong>Email</strong>: <span class="unselectable">haihua.chen</span>[at]unt.edu</p>
              <a href="https://scholar.google.com/citations?user=URmnWAQAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp;&nbsp;&nbsp;  
              <a href="https://www.linkedin.com/in/haihua-chen/">Linkedin</a> &nbsp;&nbsp;&nbsp;
              <a href="https://dblp.org/pid/49/7050-2.html">DBLP</a> &nbsp;&nbsp;&nbsp;
              <a href="https://www.researchgate.net/profile/Haihua-Chen-2">ResearchGate</a> &nbsp;&nbsp;&nbsp;
              <a href="./images/personal/01132026_HaihuaChen_CV.pdf">CV</a> 
              <p></p>
            </td>
          </tr>
        </tbody>
      </table>

      
      <!-- Bio session -->
      <a id="bio" class="anchor"></a>
      <span class="section">Brief Bio</span>
      <table border="0" class="bio" width="80%" style="margin-left: 10%; text-align: justify;">
        <tbody>
          <tr>
            <td width="80%">
              Haihua Chen is an Assistant Professor in the Anuradha and Vikas Sinha Department of Data Science and the Director of the Intelligent Data Engineering and Analytics Lab at the University of North Texas. 
              He is the current Chair of ASIS&T Special Interest Group – Scientific and Technical Information (SIG-STI). Dr. Chen’s research focuses on building high-performance and reliable artificial intelligence systems by applying natural language processing and machine learning in important domains, such as healthcare, legal, and science, with the mission of solving social problems in health, humanitarian aid, social justice, and sustainability. 
              He has coauthored more than 60 articles in prestige journals including Information Processing and Management, Knowledge-based systems, Journal of Biomedical Informatics, and others, and received nearly 1,000 citations in the last five years. 
              He is serving as co-editor for The Electronic Library, associated editor for Data Intelligence, PC chair for IEEE AITest 2025, organizing committee members for several international conferences, PC member for ACL, EMNLP, IEEE Big Data, and several top conference in NLP and AI. 

              
              <!-- I am a PhD candidate in the <a href="https://coe.northeastern.edu/">College of Engineering</a>, Northeastern University, USA and work with <a href="http://www1.ece.neu.edu/~yunfu/">Prof. Yun Raymond Fu</a> in the <a href="https://web.northeastern.edu/smilelab/">SMILE Lab</a>. 
              Before that I spent two years in the Department of Computer Sicence & Engineering, University of North Texas, working with <a href="https://www.cse.unt.edu/~song/">Prof. Song Fu</a>. 
              I received my BS and MS degrees in the College of Information Science and Technology, Nanjing Forestry University, China, advised by Prof. Yingan Liu and <a href="https://it.njfu.edu.cn/szdw/20181224/i14059.html">Prof. Qiaolin Ye</a>.  -->

              <br><br>My research interests including: Data Science, Health Informatics, Legal AI, Document Intelligence, Scientific Innovation, Generative AI, AI Applications. 

              <br><br>I am recruiting perspective Ph.D. students in Information, Data, Computer Science, and related domians (strong computational skills) will full financial support!.

              <!-- <br><br>During my PhD studies, I got some awards, ICME'20 Best Student Paper,  SEC'19 Best Paper,  NeurIPS'22 Outstanding Reviewer, CVPR'23 Outstanding Reviewer. I will serve as an Area Chair for ECCV'26. -->

            </td>
          </tr>
          <!-- <tr>
            <td width="80%">
              My research interests are in the areas of Computer Vision, and Machine Learning. 
              I was a research intern at Bell Labs, eBay, Microsoft, and Adobe.  
              I was the recipient of ICME'20 Best Student Paper Award, SEC'19 Best Paper Award, and Academic Technology Scholar Award from Northeastern University for Fall 2022.
            </td>
          </tr> -->
          <tr><td width="80%" style=" color: blue; font-size: small; ">
            <br><br><b>Research Philosophy</b>: Research is the art of transforming curiosity into innovative knowledge that enriches human understanding and society.  
            <div style="text-align: right;">-- 2025</div>
            </td></tr> 

        </tbody>
      </table>

      
      <!-- News session -->
      <a id="news" class="anchor"></a>
      <span class="section">News</span>
      <div  style="height: 350px; overflow: auto; margin-bottom: 5mm;">
        <table border="0" class="news" style="margin-left: 10%;">
          <tbody>
            <tr>
              <td>
                <p><strong>[Jan. 2026]</strong> One paper accepted by WWW 2026.</p>
                <p><strong>[Dec. 2025]</strong> I will serve as the <strong>PC Co-Chair</strong> for IEEE AITest 2026.</p>
                <p><strong>[Dec. 2025]</strong> I will attend the <a href="https://cise-re-wkshp-2025.cs.fiu.edu">NSF CISE RE Workshop</a> at FIU.</p>
                <p><strong>[Nov. 2025]</strong> Paper “<a href="https://arxiv.org/abs/2509.19326">Unveiling the Merits and Defects of LLMs in Automatic Review Generation for Scientific Papers</a>” received the Best Poster Award at <strong>IEEE ICDM'25</strong>.</p>
                <!-- <p><strong>[Mar. 2024]</strong> I will join Meta GenAI as a research intern this summer.</p>
                <p><strong>[Feb 2024]</strong> One paper “<a href="https://arxiv.org/abs/2403.19967">Rewrite the Stars</a>” has been accepted by <strong>CVPR'24</strong>.</p>
                <p><strong>[Jan. 2024]</strong> I will join Microsoft as a research intern in Spring 2024.</p>
                <p><strong>[Jan. 2023]</strong> One paper (<a href="https://openreview.net/forum?id=ip5LHJs6QX&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2024%2FConference%2FAuthors%23your-submissions))">Efficient Modulation for Vision Networks</a>)accepted by <strong>ICLR'24</strong>.</p>
                <p><strong>[Jul. 2023]</strong> Two papers accepted by <b>ICCV'23</b>.</p>
                <p><strong>[May. 2023]</strong> I will join Adobe Research as a research intern.</p> -->
                <p><strong>[Jul. 2025]</strong> Named as <b>IEEE ICAIT 2025 Best Reviewer</b>.</p>
                
              </td>
            </tr>
          </tbody>
        </table>
      </div>


      <!-- Grant session -->
      <a id="grants"></a><span class="section">Funded Research Grants </span>

      <ul style="margin-left: 10%;">
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Extenal Grants:<br></font></h3> 
        </p>
      </ul>
      
      <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px; margin-left: 7%;">
        <tbody>

          <!--Document Intelligence Survey-->
          <tr>
            <td>
              <img src="./images/publications/di-survey.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2601.12318">Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence</a></papertitle>
              <br><br>
              Dehao Ying, Fengchang Yu, <strong>Xu Ma</strong>, Changjiang Jiang, Yurong Li, Wei Lu <br>
              <strong>arXiv</strong> 2026 <br>
              <a href="https://arxiv.org/pdf/2601.12318">[arXiv]</a>
              <br><br>
            </td>
          </tr>
         
          <!--MCN Survey-->
          <tr>
            <td>
              <img src="./images/publications/mcn-all-model.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5743824">A Comprehensive Survey on Medical Concept Normalization: Datasets, Techniques, Applications, and Future Directions</a></papertitle>
              <br><br>
              <strong>Haihua Chen*</strong>, Yuhan Zhou, Ruochi Li, Aryan Murthy Illa, Ana Cleveland, Junhua Ding <br>
              <strong>SSRN</strong> 2025 <br>
              <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5743824">[SSRN]</a>
              <a href="https://github.com/haihua0913/awesome-mcn">[GitHub]</a>
              <br><br>
            </td>
          </tr>

          
          <!--EfficientMod-->
          <tr>
            <td>
              <img src="./images/efficientmod.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://openreview.net/forum?id=ip5LHJs6QX">Efficient Modulation for Vision Networks</a></papertitle>
              <br><br>
              <strong>Xu Ma</strong>, Xiyang Dai, Jianwei Yang, Bin Xiao, Yinpeng Chen, Yun Fu, Lu Yuan <br>
              <strong>ICLR</strong> 2024 <br>
              <a href="https://openreview.net/forum?id=ip5LHJs6QX">[openreivew]</a>
              <a href="https://github.com/ma-xu/EfficientMod">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--Context Cluster-->
          <tr>
            <td>
              <img src="./images/iclr23.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://openreview.net/forum?id=awnvqZja69&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2023%2FConference%2FAuthors%23your-submissions)">Image as Set of Points</a></papertitle>
              <br><br>
              <strong>Xu Ma*</strong>, <strong> Yuqian Zhou*</strong>, Huan Wang, Can Qin, Bin Sun, Chang Liu, Yun Fu <br>
              <strong>ICLR Oral</strong> 2023 <br>
              <a href="https://openreview.net/pdf?id=awnvqZja69">[openreivew]</a>
              <a href="https://github.com/ma-xu/Context-Cluster">[code]</a>
              <br><br>
            </td>
          </tr>
          
        </tbody>
      </table>

      <ul style="margin-left: 10%;">
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Internal Grants:<br></font></h3> 
        </p>
      </ul>
      
      <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px; margin-left: 7%;">
        <tbody>

          <!--Token Shuffle-->
          <tr>
            <td>
              <img src="./images/token-shuffle.jpg" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2403.19967">Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models</a></papertitle>
              <br><br>
              <strong>Xu Ma</strong>, Peize Sun, Haoyu Ma, Hao Tang, Chih-Yao Ma, Jialiang Wang, Kunpeng Li, Xiaoliang Dai, Yujun Shi, Xuan Ju, Yushi Hu, Artsiom Sanakoyeu, Felix Juefei-Xu, Ji Hou, Junjiao Tian, Tao Xu, Tingbo Hou, Yen-Cheng Liu, Zecheng He, Zijian He, Matt Feiszli, Peizhao Zhang, Peter Vajda, Sam Tsai, Yun Fu <br>
              <strong>arXiv</strong> 2025 <br>
              <a href="https://arxiv.org/abs/2504.17789">[arXiv]</a>
              <br><br>
            </td>
          </tr>
         
          <!--Rewrite the Stars-->
          <tr>
            <td>
              <img src="./images/rewrite_the_stars.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2403.19967">Rewrite the Stars</a></papertitle>
              <br><br>
              <strong>Xu Ma</strong>, Xiyang Dai, Yue Bai, Yizhou Wang, Yun Fu <br>
              <strong>CVPR</strong> 2024 <br>
              <a href="https://arxiv.org/abs/2403.19967">[arXiv]</a>
              <a href="https://github.com/ma-xu/Rewrite-the-Stars">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--EfficientMod-->
          <tr>
            <td>
              <img src="./images/efficientmod.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://openreview.net/forum?id=ip5LHJs6QX">Efficient Modulation for Vision Networks</a></papertitle>
              <br><br>
              <strong>Xu Ma</strong>, Xiyang Dai, Jianwei Yang, Bin Xiao, Yinpeng Chen, Yun Fu, Lu Yuan <br>
              <strong>ICLR</strong> 2024 <br>
              <a href="https://openreview.net/forum?id=ip5LHJs6QX">[openreivew]</a>
              <a href="https://github.com/ma-xu/EfficientMod">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--Context Cluster-->
          <tr>
            <td>
              <img src="./images/iclr23.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://openreview.net/forum?id=awnvqZja69&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2023%2FConference%2FAuthors%23your-submissions)">Image as Set of Points</a></papertitle>
              <br><br>
              <strong>Xu Ma*</strong>, <strong> Yuqian Zhou*</strong>, Huan Wang, Can Qin, Bin Sun, Chang Liu, Yun Fu <br>
              <strong>ICLR Oral</strong> 2023 <br>
              <a href="https://openreview.net/pdf?id=awnvqZja69">[openreivew]</a>
              <a href="https://github.com/ma-xu/Context-Cluster">[code]</a>
              <br><br>
            </td>
          </tr>
          
        </tbody>
      </table>
      <p>&nbsp;</p>

      
      <!-- Publication session -->
      <a id="publications" class="anchor"></a><span class="section">Selected Publications [*Corresponding author] <a href="https://scholar.google.com/citations?user=URmnWAQAAAAJ&hl=en&oi=ao">[Google Scholar]</a> </span>
      
      <ul style="margin-left: 10%;">
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Arxiv First:<br></font></h3> 
        </p>
      </ul>
      
      <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px; margin-left: 7%;">
        <tbody>

          <!--Document Intelligence Survey-->
          <tr>
            <td>
              <img src="./images/publications/di-survey.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2601.12318">Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence</a></papertitle>
              <br><br>
              Dehao Ying, Fengchang Yu, <strong>Haihua Chen</strong>, Changjiang Jiang, Yurong Li, Wei Lu <br>
              <strong>arXiv</strong> 2026 <br>
              <a href="https://arxiv.org/pdf/2601.12318">[arXiv]</a>
              <br><br>
            </td>
          </tr>


          <!--Scientific Innovation Survey-->
          <tr>
            <td>
              <img src="./images/publications/innovation-survey.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2507.11810">The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist</a></papertitle>
              <br><br>
              Haoxuan Zhang, Ruochi Li, Yang Zhang, Ting Xiao, Jiangping Chen, Junhua Ding, <strong>Haihua Chen*</strong> <br>
              <strong>arXiv</strong> 2025 <br>
              <a href="https://arxiv.org/pdf/2507.11810">[arXiv]</a>
              <a href="https://github.com/haoxuan-unt2024/llm4innovation">[GitHub]</a>
              <br><br>
            </td>
          </tr>
         
          <!--MCN Survey-->
          <tr>
            <td>
              <img src="./images/publications/mcn-all-model.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5743824">A Comprehensive Survey on Medical Concept Normalization: Datasets, Techniques, Applications, and Future Directions</a></papertitle>
              <br><br>
              <strong>Haihua Chen*</strong>, Yuhan Zhou, Ruochi Li, Aryan Murthy Illa, Ana Cleveland, Junhua Ding <br>
              <strong>SSRN</strong> 2025 <br>
              <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5743824">[SSRN]</a>
              <a href="https://github.com/haihua0913/awesome-mcn">[GitHub]</a>
              <br><br>
            </td>
          </tr>

          <!--DQ-CAV-->
          <tr>
            <td>
              <img src="./images/publications/dq-cav.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2510.16635">A Novel Multi-layer Task-centric and Data Quality Framework for Autonomous Driving</a></papertitle>
              <br><br>
              Yuhan Zhou, <strong>Haihua Chen*</strong>, Kewei Sha* <br>
              <strong>arXiv</strong> 2025 <br>
              <a href="https://arxiv.org/abs/2506.17346">[arXiv]</a>
              <!-- <a href="https://anonymous.4open.science/r/MA-SAPO-F313/README.md">[code]</a> -->
              <br><br>
            </td>
          </tr>

          
          <!--MA-SAPO-->
          <tr>
            <td>
              <img src="./images/publications/prompt-optimize.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2510.16635">Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis</a></papertitle>
              <br><br>
              Wonduk Seo, Juhyeon Lee, Junseo Koh, Hyunjin An, Jian Park, Seunghyun Lee, <strong>Haihua Chen*</strong>, Yi Bu* <br>
              <strong>arXiv</strong> 2025 <br>
              <a href="https://arxiv.org/pdf/2510.16635">[arXiv]</a>
              <a href="https://anonymous.4open.science/r/MA-SAPO-F313/README.md">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--Oral History-->
          <tr>
            <td>
              <img src="./images/publications/chord_topics.jpg" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2508.06729">Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis</a></papertitle>
              <br><br>
              Komala Subramanyam Cherukuri, Pranav Abishai Moses, Aisa Sakata, Jiangping Chen, <strong>Haihua Chen*</strong> <br>
              <strong>arXiv</strong> 2025 <br>
              <a href="https://arxiv.org/pdf/2508.06729">[arXiv]</a>
              <a href="https://github.com/kc6699c/LLM4OralHistoryAnalysis">[code]</a>
              <br><br>
            </td>
          </tr>
          
        </tbody>
      </table>

      <ul style="margin-left: 10%;">
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Journal Articles:<br></font></h3> 
        </p>
      </ul>
      
      <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px; margin-left: 7%;">
        <tbody>

           <!--2025-->
          <!--Graph-llm-->
          <tr>
            <td>
              <img src="./images/publications/grouping-result.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417425034098">A hybrid graph and LLM approach for measuring scientific novelty via knowledge recombination and propagation</a></papertitle>
              <br><br>
              Zhongyi Wang, Zereg Wang, Guangzhao Zhang, Jiangping Chen, Markus Luczak-Roesch, <strong>Haihua Chen*</strong> <br>
              <strong>Expert Systems with Applications</strong> (JCR Q1) 2025 <br>
              <a href="images/paperpdfs/%5B2025%5D%5BESWA%5D%5BA%20hybrid%20graph%20and%20LLM%20approach%20for%20measuring%20scientific%20novelty%5D.pdf">[pdf]</a>
              <a href="https://github.com/haihua0913/graphLLM4ScientificNovelty">[code]</a>
              <br><br>
            </td>
          </tr>
         
          <!--Graph-llm-->
          <tr>
            <td>
              <img src="./images/publications/ibid-model.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://www.sciencedirect.com/science/article/abs/pii/S0306457325000639">IBID-CCT: A novel model for interdisciplinary breakthrough innovation detection based on the cusp catastrophe theory</a></papertitle>
              <br><br>
              Zhongyi Wang, Na Wang, Haoxuan Zhang, Zeren Wang, Zhou Wang, Junhua Ding, <strong>Haihua Chen*</strong> <br>
              <strong>Information Processing & Management</strong> (JCR Q1) 2025 <br>
              <a href="images/paperpdfs/%5B2025%5D%5BIPM%5D%5BIBID-CCT%20A%20novel%20model%20for%20interdisciplinary%20breakthrough%20innovation%20detection%20based%20on%20the%20cusp%20catastrophe%20theory%5D%5BWang%20et%20al%5D.pdf">[pdf]</a>
              <a href="https://github.com/wolovecoding/IBID-CCT">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--mcn-llm-->
          <tr>
            <td>
              <img src="./images/publications/mcn-framework.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://www.sciencedirect.com/science/article/abs/pii/S1532046425000413">Enhancing data quality in medical concept normalization through large language models</a></papertitle>
              <br><br>
              <strong>Haihua Chen</strong>, Ruochi Li, Ana Cleveland, Junhua Ding <br>
              <strong>Journal of Biomedical Informatics</strong> (JCR Q1) 2025 <br>
              <a href="images/paperpdfs/%5B2025%5D%5BJBI%5D%5BEnhancing%20data%20quality%20in%20medical%20concept%20normalization%20through%20large%20language%20models%5D%5BChen%20et%20al.%5D.pdf">[pdf]</a>
              <a href="https://github.com/RichardLRC/mcn-data-quality-llm/tree/main/evaluation">[code]</a>
              <br><br>
            </td>
          </tr>

          <!--2024-->
          <!--Project-based Learning-->
          <tr>
            <td>
              <img src="./images/publications/eit-pbl.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://link.springer.com/article/10.1007/s10639-024-12870-1">Exploring the influence of regulated learning processes on learners’ prestige in project-based learning</a></papertitle>
              <br><br>
              Fengjiao Tu, Linjing Wu, Kinshuk, Junhua Ding, <strong>Haihua Chen*</strong> <br>
              <strong>Education and Information Technologies</strong> (JCR Q1) 2024 <br>
              <a href="images/paperpdfs/%5B2024%5D%5BEIT%5D%5BExploring%20the%20influence%20of%20regulated%20learning%20processes%20on%20learners’%20prestige%20in%20project-based%20learning%5D.pdf">[pdf]</a>
              <br><br>
            </td>
          </tr>

          <!--novelty-topic-->
          <tr>
            <td>
              <img src="./images/publications/novelty-topic.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://www.sciencedirect.com/science/article/abs/pii/S1751157724000993">An effective framework for measuring the novelty of scientific articles through integrated topic modeling and cloud model</a></papertitle>
              <br><br>
              Zhongyi Wang, Haoxuan Zhang, Jiangping Chen, <strong>Haihua Chen*</strong> <br>
              <strong>Journal of Informatics</strong> (JCR Q1) 2024 <br>
              <a href="images/paperpdfs/%5B2024%5D%5BJournal%20of%20Informatics%5D%5BAn%20effective%20framework%20for%20measuring%20the%20novelty%20of%20scientific%20articles%20through%20integrated%20topic%20modeling%20and%20cloud%20model%5D.pdf">[pdf]</a>
              <a href="https://github.com/haihua0913/MNSA-ITMCM">[code]</a>
              <br><br>
            </td>
          </tr>

          
        </tbody>
      </table>
      
      <ul style="margin-left: 10%;">
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Conference Papers:<br></font></h3> 
        </p>
      </ul>
      
      <table border="0" width="95%" class="paper" style="border-collapse:separate; border-spacing:10px; margin-left: 7%;">
        <tbody>

          <!--TableDSR-->
          <tr>
            <td>
              <img src="./images/publications/tabdsr.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://aclanthology.org/2025.findings-emnlp.169/">TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data</a></papertitle>
              <br><br>
              Changjiang Jiang, Fengchang Yu, <strong>Haihua Chen</strong>, Wei Lu, Jin Zeng <br>
              Findings of the Association for Computational Linguistics: <strong>EMNLP</strong> 2025 <br>
              <a href="https://aclanthology.org/2025.findings-emnlp.169.pdf">[pdf]</a>
              <br><br>
            </td>
          </tr>
         
          <!--Rewrite the Stars-->
          <tr>
            <td>
              <img src="./images/rewrite_the_stars.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://arxiv.org/abs/2403.19967">Rewrite the Stars</a></papertitle>
              <br><br>
              <strong>Xu Ma</strong>, Xiyang Dai, Yue Bai, Yizhou Wang, Yun Fu <br>
              <strong>CVPR</strong> 2024 <br>
              <a href="https://arxiv.org/abs/2403.19967">[arXiv]</a>
              <a href="https://github.com/ma-xu/Rewrite-the-Stars">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--EfficientMod-->
          <tr>
            <td>
              <img src="./images/efficientmod.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://openreview.net/forum?id=ip5LHJs6QX">Efficient Modulation for Vision Networks</a></papertitle>
              <br><br>
              <strong>Xu Ma</strong>, Xiyang Dai, Jianwei Yang, Bin Xiao, Yinpeng Chen, Yun Fu, Lu Yuan <br>
              <strong>ICLR</strong> 2024 <br>
              <a href="https://openreview.net/forum?id=ip5LHJs6QX">[openreivew]</a>
              <a href="https://github.com/ma-xu/EfficientMod">[code]</a>
              <br><br>
            </td>
          </tr>

          
          <!--Context Cluster-->
          <tr>
            <td>
              <img src="./images/iclr23.png" width="200" height="110" style="margin-right: 15px;">
            </td>
            <td>
              <papertitle><a href="https://openreview.net/forum?id=awnvqZja69&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2023%2FConference%2FAuthors%23your-submissions)">Image as Set of Points</a></papertitle>
              <br><br>
              <strong>Xu Ma*</strong>, <strong> Yuqian Zhou*</strong>, Huan Wang, Can Qin, Bin Sun, Chang Liu, Yun Fu <br>
              <strong>ICLR Oral</strong> 2023 <br>
              <a href="https://openreview.net/pdf?id=awnvqZja69">[openreivew]</a>
              <a href="https://github.com/ma-xu/Context-Cluster">[code]</a>
              <br><br>
            </td>
          </tr>
          
        </tbody>
      </table>
      <p>&nbsp;</p>


      <!-- Teaching session -->
      <a id="teaching"></a><span class="section">Teaching</span>
      <ul style="margin-left: 10%;">
        <li><h4>Best paper of SEC 2019</h4></li>
        <li><h4>Best student paper of ICME 2020</h4></li>
        <li><h4>Outstanding Reviewer of NeurIPS  2022</h4></li>
        <li><h4>Outstanding Reviewer of CVPR  2023</h4></li>
        <li><h4>Academic Technology Scholar from Northeastern University 2022 Fall</h4></li>
      </ul>

      
      <!-- Service session -->
      <a id="awards"></a><span class="section">Services and Reviews </span>
      <ul style="margin-left: 10%;">

        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Area Chair of Conferences:<br></font></h3> 
        ECCV 2026
        </p>

        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Reviewer of Journals:<br></font></h3>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)<br>
        IEEE Transactions on Image Processing (TIP)<br>
        IEEE Transactions on Multimedia (TMM) <br>
        IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) <br>
        IEEE Signal Processing Letters (SPL) <br>
        IEEE Transactions on Intelligent Vehicles (TIV)<br>
        </p>
        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Reviewer of Conferences:<br></font></h3>
        CVPR, ICCV, ECCV, ICML, ICLR, NeurIPS, SIGGRAPH Asia, KDD, AAAI, IJCAI, ACM MM, WACV, ICME, FG, ICASSP
        </p>
        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Reviewer of Workshops:<br></font></h3>
        <a href="https://sites.google.com/view/ecv23">Efficient Deep Learning for Computer Vision (ECV) @ CVPR</a>  <br>
        <a href="https://sites.google.com/view/t4v-cvpr23">Transformers for Vision (T4V) @ CVPR</a>   <br>
        <a href="https://ijcai-23.org/call-for-papers-ai-and-social-good/">AI and Social Good @ IJCAI</a>   <br>
        <a href="https://web.northeastern.edu/smilelab/amfg2023/">Analysis and Modeling of Faces and Gestures (AMFG) @ ICCV</a>   <br>
        </p>
        <!-- <li>
          <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
            <font color="#444444" face="Lato" ><font color="#444444" face="Lato" ><b><font color="#444444" face="Lato">
              Reviewer of Journals: <br>
              IEEE Transactions on Image Processing, IEEE Signal Processing Letters, IEEE Transactions on Intelligent Vehicles </font></b></font></font></b></p>
          </li>
          
          <li>
          <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
            <font color="#444444" face="Lato"><font color="#444444" face="Lato"><b><font color="#444444" face="Lato">
              Reviewer of Conferences: <br>WACV 20; ICME 21,22,23;  IJCAI 22,23;  FG 21,23;  CVPR 22,23; ECCV 22;  NeurIPS 22; SIGGRAPH Asia 23; ACMMM 22;  AAAI 23;  ICASSP 23; KDD 23</font></b></font></font></b></p>
          </li>
          <br><br> -->
      </ul>

      
      <!-- Awards session -->
      <a id="honors"></a><span class="section">Honors & Awards</span>
      <ul style="margin-left: 10%;">
        <li><h4>Best paper of SEC 2019</h4></li>
        <li><h4>Best student paper of ICME 2020</h4></li>
        <li><h4>Outstanding Reviewer of NeurIPS  2022</h4></li>
        <li><h4>Outstanding Reviewer of CVPR  2023</h4></li>
        <li><h4>Academic Technology Scholar from Northeastern University 2022 Fall</h4></li>
      </ul>

      <!-- Team session -->
      <a id="team" class="anchor"></a><span class="section">Students </span>
      <ul style="margin-left: 10%;">
      <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 4pt;">
        <h3><font color="#444444" face="Lato">I have been fortunate to work with many gifted students:<br></font></h3> 
        </p>

        <font color="#444444" face="Lato" size="3">    
      
         
         <li> <a href="https://shivamduggal4.github.io/">  Shivam Duggal </a> (MIT), 2023  </li>           
         <li> <a href="https://ymingxie.github.io/">  Yiming Xie </a> (Northeastern University), 2023  </li>            
         <li> <a href="">  Xiaoyu Zhou </a> (Peking University), 2023  </li>           
         <li> <a href="https://www.junyi42.com/">  Junyi Zhang </a> (Shanghai Jiao Tong University), 2023  </li>       
         <li> <a href="https://kovenyu.com/">  Hong-Xing "Koven" Yu </a> (Stanford University), 2022-2023  </li>   
         <li> <a href="https://markboss.me/">  Mark Boss </a> (University of Tübingen &#8594; Unity), 2021  </li>   
         <li>  <a href="https://hhsinping.github.io/">Hsin-Ping Huang</a> (UC Merced), 2021-2023  </li>   
         <li> <a href="https://www.linkedin.com/in/kyle-sargent-784006134/"> Kyle Sargent  </a> (Google AI Resident &#8594; PhD student at Stanford), 2021-2023  </li>
         <li> <a href="https://scholar.google.com/citations?user=LQvi5XAAAAAJ&hl=en">   Charles Herrmann </a> (Cornell &#8594; Google), 2020-2021  </li>    
         <li> <a href="https://reagan1311.github.io/">Gen Li</a> (University of Edinburgh), 2020-2023  </li>
         <li> <a href="https://zudi-lin.github.io/"> Zudi Lin </a> ( Harvard &#8594; Amazon ), 2020-2021  </li>
        <li> <a href="https://songhwanjun.github.io/"> Hwanjun Song </a> (KAIST &#8594; NAVER AI Lab), 2020-2021  </li>
         <li> <a href="https://scholar.google.com/citations?user=qsrpuKIAAAAJ&hl=en">Feitong Tan</a> (SFU &#8594; Google), 2020  </li>   
         <li> <a href="https://gengshan-y.github.io/">Gengshan Yang</a> (CMU &#8594; Meta), 2020-2021  </li>
         <li><a href="https://rakeshjasti.github.io/">Rakesh Jasti</a> (UC Merced), 2019</li>
         <li> <a href="https://scholar.harvard.edu/jwang">  Jialiang Wang </a> (Harvard &#8594; Facebook), 2019-2020  </li>   
         <li> <a href="https://prinsphield.github.io/">Taihong Xiao </a> (UC Merced), 2019 </li>
         <li> <a href="http://www.xyang35.umiacs.io/"> Xitong Yang </a> (University of Maryland &#8594; Meta), 2019  </li>
         <li> <a href="http://graduatestudents.ucmerced.edu/wlai24/">Wei-Sheng Lai</a> (UC Merced &#8594; Google), 2018-2019  </li>
         <li> <a href="https://anuragranj.github.io/"> Anurag Ranjan   </a> (Max Planck Institute for Intelligent Systems  &#8594; Apple), 2018  </li>   
         <li> <a href="https://scholar.google.com/citations?user=DBydn38AAAAJ&hl=en"> Wei-Chih Tu </a> (National Taiwan University &#8594; Ganzin), 2017  </li>
         <li> <a href="https://scholar.google.com/citations?user=ruebFVEAAAAJ&hl=en&oi=ao">  Jiangxin Dong</a> ( DUST &#8594; Max Planck Institute for Informatics), 2017-2018 </li>
         <li> <a href="https://jianghz.me/">  Huaizu Jiang </a> ( UMass Amherst &#8594; Northeastern), 2017-2019  </li>
         <li> <a href="https://lvzhaoyang.github.io/">   Zhaoyang Lv  </a> (Georgia Tech &#8594; Facebook), 2017, 2019  </li> 
         <li> <a href="https://suhangpro.github.io/">  Hang Su </a> ( UMass Amherst &#8594; NVIDIA Research), 2017-2018  </li>
         <li> <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai </a>(UC Merced &#8594; NEC Lab &#8594; Phiar ), 2017  </li>
        <li> <a href="https://jrenzhile.com/">Zhile Ren</a> (Brown &#8594; Georgia Tech &#8594; Apple), 2016-2017  </li>
        <li><a href="https://sites.google.com/corp/view/xiangyuxu">Xiangyu Xu</a> (Tsinghua/UC Merced &#8594; CMU/MIT &#8594; NTU), 2016-2017 </li>
        <li> <a href="https://jspan.github.io/">Jinshan Pan</a> (DUST/UC Merced &#8594;  NUST), 2015  </li>
      <!-- <li> <a href=" ">  </a> ( &#8594; )  </li> -->
        </font>
        </ul>

      
      <!-- Resource session -->
      <a id="resources"></a><span class="section">Resoruces </span>
      <ul style="margin-left: 10%;">

        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Area Chair of Conferences:<br></font></h3> 
        ECCV 2026
        </p>

        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Reviewer of Journals:<br></font></h3>
        IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)<br>
        IEEE Transactions on Image Processing (TIP)<br>
        IEEE Transactions on Multimedia (TMM) <br>
        IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) <br>
        IEEE Signal Processing Letters (SPL) <br>
        IEEE Transactions on Intelligent Vehicles (TIV)<br>
        </p>
        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Reviewer of Conferences:<br></font></h3>
        CVPR, ICCV, ECCV, ICML, ICLR, NeurIPS, SIGGRAPH Asia, KDD, AAAI, IJCAI, ACM MM, WACV, ICME, FG, ICASSP
        </p>
        <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;">
        <h3><font color="#444444" face="Lato">Reviewer of Workshops:<br></font></h3>
        <a href="https://sites.google.com/view/ecv23">Efficient Deep Learning for Computer Vision (ECV) @ CVPR</a>  <br>
        <a href="https://sites.google.com/view/t4v-cvpr23">Transformers for Vision (T4V) @ CVPR</a>   <br>
        <a href="https://ijcai-23.org/call-for-papers-ai-and-social-good/">AI and Social Good @ IJCAI</a>   <br>
        <a href="https://web.northeastern.edu/smilelab/amfg2023/">Analysis and Modeling of Faces and Gestures (AMFG) @ ICCV</a>   <br>
        </p>
        <!-- <li>
          <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
            <font color="#444444" face="Lato" ><font color="#444444" face="Lato" ><b><font color="#444444" face="Lato">
              Reviewer of Journals: <br>
              IEEE Transactions on Image Processing, IEEE Signal Processing Letters, IEEE Transactions on Intelligent Vehicles </font></b></font></font></b></p>
          </li>
          
          <li>
          <p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b>
            <font color="#444444" face="Lato"><font color="#444444" face="Lato"><b><font color="#444444" face="Lato">
              Reviewer of Conferences: <br>WACV 20; ICME 21,22,23;  IJCAI 22,23;  FG 21,23;  CVPR 22,23; ECCV 22;  NeurIPS 22; SIGGRAPH Asia 23; ACMMM 22;  AAAI 23;  ICASSP 23; KDD 23</font></b></font></font></b></p>
          </li>
          <br><br> -->
      </ul>




      <div style=" width: 30%; height: 5cm; margin-left: 35%; margin-top: 10mm;">
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=n&d=0fy2G3f1bJ1gwddxo3-AyBeEjFBu3GQdJtb4LY8j7ls'></script>
      </div>
      <p>
        <font color="#444444" face="Lato" size="2">© 2025 Haihua Chen. Thanks to <a href="https://ma-xu.github.io"><font color="#000080">Xu Ma</font></a> and 
        <a href="https://deqings.github.io/index.html"><font color="#000080">Dr. Deqing Sun</font></a> for the template. </font>
        <font color="orange" face="Lato" size="2">[Updated: Nov/2024]</font>
      </p>
      <!-- </div> -->
      <!-- <script>
        var thumbnails = document.getElementsByClassName("PaperThumbnail");
        var i;
        for (i = 0; i < thumbnails.length; i++) {
          thumbnails[i].width = "120"
        }
        </script>   -->
    </div>
  </body>
</html>
